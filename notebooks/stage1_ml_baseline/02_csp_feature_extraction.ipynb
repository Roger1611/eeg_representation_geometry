{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c11fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4e7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    import os, random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddec6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('preprocessed.npz'):\n",
    "    raise FileNotFoundError(\"Save preprocessed epochs as 'preprocessed.npz' with arrays X,y and optional meta.\")\n",
    "d = np.load(\"preprocessed.npz\", allow_pickle=True)\n",
    "X = d[\"X\"]\n",
    "y = d[\"y\"]\n",
    "meta = d[\"meta\"].item() if d[\"meta\"].shape == () else dict(d[\"meta\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1d5462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (30, 64, 561)\n",
      "y.shape = (30,)\n",
      "meta = {}\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape =\", X.shape)\n",
    "print(\"y.shape =\", y.shape)\n",
    "print(\"meta =\", meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8537027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00082 (2.2e-16 eps * 64 dim * 5.8e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computed CSP features: (30, 8)\n"
     ]
    }
   ],
   "source": [
    "USE_CSP = True\n",
    "CSP_COMPONENTS = 8\n",
    "if USE_CSP:\n",
    "    from mne.decoding import CSP\n",
    "    csp = CSP(n_components=CSP_COMPONENTS, log=True, norm_trace=False)\n",
    "    X_csp = csp.fit_transform(X, y)  # shape (n_epochs, n_components)\n",
    "    print(\"Computed CSP features:\", X_csp.shape)\n",
    "else:\n",
    "    X_csp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5670c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CSP] LDA: acc=0.967 ± 0.067, f1=0.966\n",
      "[CSP] SVM-rbf: acc=0.967 ± 0.067, f1=0.966\n",
      "[CSP] RandomForest: acc=1.000 ± 0.000, f1=1.000\n",
      "[CSP] MLP: acc=1.000 ± 0.000, f1=1.000\n"
     ]
    }
   ],
   "source": [
    "classical_models = {\n",
    "    'LDA': Pipeline([('sc', StandardScaler()), ('clf', LinearDiscriminantAnalysis())]),\n",
    "    'SVM-rbf': Pipeline([('sc', StandardScaler()), ('clf', SVC(kernel='rbf', C=1, probability=True))]),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'MLP': Pipeline([('sc', StandardScaler()), ('clf', MLPClassifier(hidden_layer_sizes=(100,), max_iter=400))])\n",
    "}\n",
    "\n",
    "CV_SPLITS = 5\n",
    "results_classical = {}\n",
    "if X_csp is not None:\n",
    "    skf = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=42)\n",
    "    for name, clf in classical_models.items():\n",
    "        accs=[]; f1s=[]\n",
    "        for tr, te in skf.split(X_csp, y):\n",
    "            clf.fit(X_csp[tr], y[tr])\n",
    "            p = clf.predict(X_csp[te])\n",
    "            accs.append(accuracy_score(y[te], p))\n",
    "            f1s.append(f1_score(y[te], p, average='weighted'))\n",
    "        results_classical[name] = {'acc_mean': float(np.mean(accs)), 'acc_std': float(np.std(accs)),\n",
    "                                   'f1_mean': float(np.mean(f1s)), 'f1_std': float(np.std(f1s))}\n",
    "        print(f\"[CSP] {name}: acc={results_classical[name]['acc_mean']:.3f} ± {results_classical[name]['acc_std']:.3f}, f1={results_classical[name]['f1_mean']:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1df63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self,X,y): self.X=X.astype(np.float32); self.y=y.astype(np.int64)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self,idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, chans, samples, classes=2, kern_len=64, F1=8, D=2, F2=16, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kern_len), padding=(0, kern_len//2), bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.Conv2d(F1, F1*D, (chans, 1), bias=False),\n",
    "            nn.BatchNorm2d(F1*D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1,4)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.second = nn.Sequential(\n",
    "            nn.Conv2d(F1*D, F2, (1, 16), bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1,8)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy=torch.zeros(1,1,chans,samples)\n",
    "            feat=self.first(dummy); feat=self.second(feat)\n",
    "            hid_dim=feat.shape[1]\n",
    "        self.classify = nn.Linear(hid_dim, classes)\n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(1); x = self.first(x); x = self.second(x); return self.classify(x)\n",
    "\n",
    "def train_epoch(model, loader, opt, loss_fn, device='cpu'):\n",
    "    model.train(); losses=[]\n",
    "    for xb,yb in loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(); logits=model(xb); loss=loss_fn(logits,yb); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "def eval_model_preds(model, loader, device='cpu'):\n",
    "    model.eval(); ys=[]; preds=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            xb=xb.to(device); logits=model(xb)\n",
    "            p=logits.argmax(dim=1).cpu().numpy()\n",
    "            preds.extend(p.tolist()); ys.extend(yb.numpy().tolist())\n",
    "    return np.array(ys), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2afe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels (raw): [0 1]\n",
      "min, max: 0 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch\n",
    "d = np.load('preprocessed.npz', allow_pickle=True)\n",
    "y = d['y'].astype(int)\n",
    "print(\"unique labels (raw):\", np.unique(y))\n",
    "print(\"min, max:\", y.min(), y.max())\n",
    "\n",
    "# if you already created model:\n",
    "# print(\"model output dim (last linear out_features):\", model.classify.out_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bcab3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fix: [0 1]\n",
      "After fix (should be 0 and 1): [0 1]\n",
      "Saved corrected preprocessed.npz!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load the file\n",
    "d = np.load(\"preprocessed.npz\", allow_pickle=True)\n",
    "X = d[\"X\"]\n",
    "y = d[\"y\"].astype(int)\n",
    "meta_raw = d[\"meta\"]\n",
    "meta = meta_raw.item() if meta_raw.shape == () else dict(meta_raw)\n",
    "\n",
    "print(\"Before fix:\", np.unique(y))\n",
    "\n",
    "# FIX: zero-index the labels\n",
    "y_fixed = y - y.min()\n",
    "\n",
    "print(\"After fix (should be 0 and 1):\", np.unique(y_fixed))\n",
    "\n",
    "# save corrected file\n",
    "np.savez_compressed(\"preprocessed.npz\", X=X, y=y_fixed, meta=meta)\n",
    "\n",
    "print(\"Saved corrected preprocessed.npz!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcec3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels now: [0 1]\n"
     ]
    }
   ],
   "source": [
    "d = np.load('preprocessed.npz', allow_pickle=True)\n",
    "print(\"Labels now:\", np.unique(d['y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a742701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EEGNet] ep1: tr_loss=0.7086, test_acc=0.5000, f1=0.3333\n",
      "[EEGNet] ep5: tr_loss=0.3813, test_acc=0.5000, f1=0.3333\n",
      "[EEGNet] ep10: tr_loss=0.2437, test_acc=0.5000, f1=0.3333\n",
      "[EEGNet] ep15: tr_loss=0.1374, test_acc=0.5000, f1=0.3333\n",
      "[EEGNet] ep20: tr_loss=0.0937, test_acc=0.5000, f1=0.3333\n",
      "[EEGNet] ep25: tr_loss=0.0433, test_acc=0.5000, f1=0.3333\n",
      "EEGNet best acc: 0.5 at epoch 1\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_epochs, n_chans, n_times = X.shape\n",
    "tr_idx, te_idx = train_test_split(np.arange(n_epochs), test_size=0.2, stratify=y, random_state=42)\n",
    "train_loader = DataLoader(EEGDataset(X[tr_idx], y[tr_idx]), batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(EEGDataset(X[te_idx], y[te_idx]), batch_size=64, shuffle=False)\n",
    "\n",
    "model = EEGNet(n_chans, n_times, classes=len(np.unique(y))).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "EPOCHS = 25\n",
    "best_acc=0; best_epoch=0\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss = train_epoch(model, train_loader, opt, loss_fn, device)\n",
    "    ys, preds = eval_model_preds(model, test_loader, device)\n",
    "    acc = accuracy_score(ys, preds); f1v = f1_score(ys, preds, average='weighted')\n",
    "    if acc > best_acc: best_acc=acc; best_epoch=ep; torch.save(model.state_dict(), 'eegnet_best.pth')\n",
    "    if ep==1 or ep%5==0: print(f\"[EEGNet] ep{ep}: tr_loss={tr_loss:.4f}, test_acc={acc:.4f}, f1={f1v:.4f}\")\n",
    "print(\"EEGNet best acc:\", best_acc, \"at epoch\", best_epoch)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d55f0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {np.int64(0): np.int64(14), np.int64(1): np.int64(16)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = np.load(\"preprocessed.npz\", allow_pickle=True)\n",
    "y = d[\"y\"]\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Labels:\", dict(zip(unique, counts)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
